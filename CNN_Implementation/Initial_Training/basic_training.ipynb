{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN IMPLEMENTATION TO CLASSIFY HANDWRITTEN DIGITS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPLEMENTATION CONCEPT : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using CNN model to detect hand written digits from MNIST dataset. We will tune different model parameters and find out the best model for our usecase. Then we will save that model and load it into my flask application for Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is MNIST dataset ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST (Modified National Institute of Standards and Technology) dataset is a large collection of handwritten digits. It consists of 70,000 grayscale images of digits (0-9), each sized 28x28 pixels. The dataset is split into a training set of 60,000 images and a test set of 10,000 images. Each image is labeled with the corresponding digit it represents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is CNN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Convolutional Neural Network (CNN) is a deep learning model designed for image processing tasks. It consists of convolutional layers that use filters to scan the image and extract features, activation functions like ReLU to introduce non-linearity, and pooling layers to reduce spatial dimensions and computational load. Following these, fully connected layers combine the extracted features to make final predictions. The output layer, typically using a softmax function for classification, provides the probability distribution over class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How am I going to use CNN ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using CNN model to learn the patterns within the images in the dataset. I will be using multiple convolution layers, droupout layers and activation functions to learn the patterns. For learning Optimization, i will be normalizing the data and also use batch normalization and different number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  -- CODING STARTS HERE --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THESE ARE THE LIBRARIES NEEEDED TO RUN THE CNN MODEL IN PYTORCH.\n",
    "# SKLEARN IS USED TO IMPORT THE DATASET.\n",
    "# MATPLOTLIB IS USED TO PLOT THE IMAGES.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import fetch_openml\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET MANUPILATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset using pytorch only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to make them in tensor \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Converts PIL Image or numpy.ndarray to tensor\n",
    "])\n",
    "\n",
    "# Load the full MNIST dataset\n",
    "full_train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "full_test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Extract x_train, y_train, x_test, y_test\n",
    "x_train = full_train_data.data.float() / 255.0\n",
    "y_train = full_train_data.targets\n",
    "x_test = full_test_data.data.float() / 255.0\n",
    "y_test = full_test_data.targets\n",
    "\n",
    "# Optionally, split into training and validation sets\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Print shapes for verification\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE IMAGES ARE NORMALIZED TO A VALUE BETWEEN 0 AND 1.\n",
    "# THIS IS DONE TO IMPROVE THE TRAINING PROCESS.\n",
    "# WHAT HAPPENS IF NOT NORMALIZED?\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# If we do not normalize the data: The learning process may become slower and less efficient.\n",
    "# as features with larger ranges can dominate gradient updates, leading to slower convergence. \n",
    "# This can result in poor model performance, \n",
    "# as models using gradient descent may be disproportionately influenced by features with larger scales.\n",
    "#  Additionally, the lack of normalization complicates hyperparameter. Making it difficult to compare the importance of different features. \n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE USE PRINT STATEMENTS TO CHECK THE SHAPE OF THE TRAINING AND TESTING DATA.\n",
    "# THE SHAPE OF THE TRAINING DATA IS (60000, 28, 28) AND THE TESTING DATA IS (10000, 28, 28).\n",
    "# THE SHAPE OF THE TRAINING LABELS IS (60000,) AND THE TESTING LABELS IS (10000,).\n",
    "# THIS HELPS US IDENTIFY WHAT INPUT PARATMETERS AND OUTPUT PARAMETERS TO USE FOR THE CNN MODEL\n",
    "\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATPLOTLIB IS USED TO PLOT THE IMAGES/ GRAPHS TO VISUALIZE THE DATA.\n",
    "# THE FUNCTION BELOW PLOTS THE FIRST 5 SAMPLES FROM THE TRAINING SET.\n",
    "\n",
    "def plot(x, y, num_samples=5):\n",
    "    plt.figure(figsize=(10, 2)) # Set the size of the plot\n",
    "    for i in range(num_samples): \n",
    "        plt.subplot(1, num_samples, i + 1) # Create a subplot\n",
    "        plt.imshow(x[i], cmap='gray') # Display an image\n",
    "        plt.title(f\"Label: {y[i]}\")     # Set the title of the image\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the first 5 samples from the training set\n",
    "plot(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERSION OF NUMPY ARRAYS TO TENSORS IN PYTORCH\n",
    "# THIS IS NEEDED BECAUSE PYTORCH WORKS WITH TENSORS. \n",
    "# IT IS OPTIMIZED FOR CALCULATIONS ON TENSORS.\n",
    "# IT ALLOWS FOR PARALLEL COMPUTATIONS\n",
    "# THE TENSORS ARE USED TO CREATE THE DATASET AND DATALOADER IN THE NEXT CODE\n",
    "\n",
    "x_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "x_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING A CHANNEL DIMENSION TO TENSORS\n",
    "# THIS IS BEACUSE The MNIST IMAGES ARE GRAY SCALE OF SHAPE (28, 28). \n",
    "# PyTorch models typically expect an additional channel dimension (1, 28, 28)\n",
    "\n",
    "x_train_tensor = x_train_tensor.unsqueeze(1)\n",
    "x_test_tensor = x_test_tensor.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE WE CHECK THE TYPE AND SHAPE OF THE TENSORS\n",
    "# WE CAN SEE THAT THE TENSORS HAVE BEEN CONVERTED TO FLOAT32 AND LONG DATA TYPES.\n",
    "# THE SHAPE OF THE TRAINING DATA IS (60000, 1, 28, 28) AND THE TESTING DATA IS (10000, 1, 28, 28).\n",
    "# THIS IS THE FORMAT THAT PYTORCH REQUIRES\n",
    "\n",
    "print(type(x_train_tensor), x_train_tensor.shape)\n",
    "print(type(y_train_tensor), y_train_tensor.shape)\n",
    "print(type(x_test_tensor), x_test_tensor.shape)\n",
    "print(type(y_test_tensor), y_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A FULL TRAINING DATASET USING THE TENSORS\n",
    "# HERE WE COMBINE THE DATA AND ITS LABEL. \n",
    "# THIS MAKES IT EASIER FOR ME TO MANAGE THE DATA WHILE SENDING IT TO THE MODEL.\n",
    "full_train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "\n",
    "\n",
    "# AS A REQUIREMENT IN THE ASSIGNMENT. WE SPLIT THE FULL TRAINING DATASET INTO TRAINING AND VALIDATION SETS.\n",
    "# THE TRAINING DATASET IS 80% OF THE FULL TRAINING DATASET AND THE VALIDATION DATASET IS 20% OF THE FULL TRAINING DATASET.\n",
    "# THIS IS DONE TO EVALUATE THE MODEL PERFORMANCE ON UNSEEN DATA.\n",
    "train_size = int(0.8 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYTORCH IS EZ WITH DATALOADER\n",
    "# DATALOADER IS USED TO LOAD THE DATA IN BATCHES.\n",
    "# THIS IS DONE TO IMPROVE THE TRAINING PROCESS.\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1000, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(x_test_tensor, y_test_tensor), batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKING OF CUDA GPU AVALABILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS LINE OF CODE CHECKS FOR THE DEVICE AVAILABLE.\n",
    "# IF A GPU IS AVAILABLE, THE DEVICE IS SET TO CUDA. OTHERWISE, THE DEVICE IS SET TO CPU.\n",
    "# THIS CHECK IS IMPORTANT BECAUSE PYTORCH CAN RUN ON BOTH CPU AND GPU.\n",
    "# RUNNING ON GPU IS FASTER THAN RUNNING ON CPU.\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THESE ARRAYS TRACK THE EVALUATION METRICS OF THE MODEL.\n",
    "# THIS WILL HELP US IDENTIFY THE BEST MODEL.\n",
    "\n",
    "arruracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "F1Score = []\n",
    "allmodels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL ARCHITECTURE AND DESIGN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 1 DEFINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE CNN MODEL IS DEFINED BELOW\n",
    "# THE CNN MODEL CONSISTS OF TWO CONVOLUTIONAL LAYERS AND TWO FULLY CONNECTED LAYERS\n",
    "# A MAX POOLING LAYER IS USED TO REDUCE THE DIMENSIONALITY OF THE DATA\n",
    "# THIS MAX POOL LAYER IS APPLIED BETWEEN THE CONVOLUTIONAL LAYERS AND THE FULLY CONNECTED LAYERS\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    # THIS FUNCTION DESCRIBES THE FORWARD PASS OF THE CNN MODEL \n",
    "    # THE FORWARD FUNCTION DESCRIBES HOW THE DATA FLOWS THROUGH THE NETWORK\n",
    "    # THE RELU ACTIVATION FUNCTION IS USED AFTER EACH CONVOLUTIONAL LAYER AND FULLY CONNECTED LAYER\n",
    "    # THE RELU FUNCTION IS USED TO INTRODUCE NON-LINEARITY INTO THE MODEL\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 1 TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE IS THE CODE THAT ITERATES THROUGH THE MODEL AND TRAINS IT\n",
    "# THE MODEL IS INTILIAZED WITH THE CNN CLASS\n",
    "# THEN THE FOLLOWING ARE DEFINED:\n",
    "# THE LOSS FUNCTION (CROSS ENTROPY LOSS)\n",
    "# THE OPTIMIZER (ADAM OPTIMIZER)\n",
    "# THE LEARNING RATE (0.001)\n",
    "# THE NUMBER OF EPOCHS (8)\n",
    "\n",
    "\n",
    "# THEN EVALUATION IS PERFORMED: \n",
    "# THE TRAINING LOOP ITERATES THROUGH THE TRAINING DATA AND UPDATES THE WEIGHTS OF THE MODEL\n",
    "# THE MODEL IS THEN EVALUATED ON THE VALIDATION DATA TO CHECK FOR OVERFITTING\n",
    "\n",
    "model0 = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model0.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 8\n",
    "for epoch in range(num_epochs):\n",
    "    model0.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model0(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model0.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model0(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f\"Validation Loss: {val_loss / len(val_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEHSE LIBRAIES ARE NEEDED TO EVALUATE THE MODEL\n",
    "# THE ACCURACY, PRECISION, RECALL, F1 SCORE AND CONFUSION MATRIX ARE USED TO EVALUATE THE MODEL\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS FUNCTION EVALUATES THE MODEL ON THE TEST DATA\n",
    "# THEN IT PRINTS IS ACCURACY, PRECISION, RECALL, F1 SCORE AND CONFUSION MATRIX\n",
    "# THE CONFUSION MATRIX IS PLOTTED TO VISUALIZE THE PERFORMANCE OF THE MODEL\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall = recall_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "    # save them into the arrays for tracking\n",
    "    arruracy.append(accuracy)\n",
    "    precision.append(precision)\n",
    "    recall.append(recall)\n",
    "    F1Score.append(f1)\n",
    "    \n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model0, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOW TO IMPROVE THE MODEL ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have created a basic CNN model, choose some hyperparameters for it and training on the dataset. Then I evaluated the model in unseen test data. This was to get the basic idea od how my model responds to CNN architecture and what should i be doing next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE :  Although i believe the complexity of the model i enough, It is the requirment to make the model deeper. hence i Will increase the convolution layers, batch normalization layers and Pooling layers in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # THE CNN MODEL IS DEFINED BELOW\n",
    "    # THE CNN MODEL CONSISTS OF THREE CONVOLUTIONAL LAYERS AND TWO FULLY CONNECTED LAYERS\n",
    "    # A MAX POOLING LAYER IS USED TO REDUCE THE DIMENSIONALITY OF THE DATA\n",
    "    # THIS MAX POOL LAYER IS APPLIED BETWEEN THE CONVOLUTIONAL LAYERS AND THE FULLY CONNECTED LAYERS\n",
    "    # A DROPOUT LAYER IS USED TO PREVENT OVERFITTING\n",
    "\n",
    "    # THE FIRST CONV LAYER HAS 32 FILTERS, THE SECOND CONV LAYER HAS 64 FILTERS AND THE THIRD CONV LAYER HAS 128 FILTERS\n",
    "    # THE STRIDE OF 1 MEANS THAT THE FILTER MOVES ONE PIXEL AT A TIME\n",
    "    # THE PADDING OF 1 MEANS THAT THE INPUT IMAGE IS PADDDED WITH ZEROS TO MAINTAIN THE SAME DIMENSIONALITY\n",
    "    # THE KERNEL SIZE OF 3 MEANS THAT THE FILTER SIZE IS 3X3\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "    \n",
    "    # THIS FUNCTION DESCRIBES THE FORWARD PASS OF THE CNN MODEL\n",
    "    # THE FORWARD FUNCTION DESCRIBES HOW THE DATA FLOWS THROUGH THE NETWORK\n",
    "    # THE RELU ACTIVATION FUNCTION IS USED AFTER EACH CONVOLUTIONAL LAYER AND FULLY CONNECTED LAYER\n",
    "    # THE RELU FUNCTION IS USED TO INTRODUCE NON-LINEARITY INTO THE MODEL\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(-1, 128 * 3 * 3)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL 2 TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE IS THE CODE THAT ITERATES THROUGH THE MODEL AND TRAINS IT\n",
    "# THE MODEL IS INTILIAZED WITH THE CNN CLASS\n",
    "# THEN THE FOLLOWING ARE DEFINED:\n",
    "# THE LOSS FUNCTION (CROSS ENTROPY LOSS)\n",
    "# THE OPTIMIZER (ADAM OPTIMIZER)\n",
    "# THE LEARNING RATE (0.001)\n",
    "# THE NUMBER OF EPOCHS (8)\n",
    "\n",
    "\n",
    "# THEN EVALUATION IS PERFORMED: \n",
    "# THE TRAINING LOOP ITERATES THROUGH THE TRAINING DATA AND UPDATES THE WEIGHTS OF THE MODEL\n",
    "# THE MODEL IS THEN EVALUATED ON THE VALIDATION DATA TO CHECK FOR OVERFITTING\n",
    "\n",
    "model1 = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model1.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device) \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model1(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model1.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device) \n",
    "            outputs = model1(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f\"Validation Loss: {val_loss / len(val_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model1, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WHAT HAPPENED?\n",
    "\n",
    "Here we see that the accuracy of the model decreased as we increased the complexity. I.e. number of layers. This can be a good sign as model is learning the patterns in the images frovided rather then just overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TWEAKING MODEL AND USING DIFFERENT ACTIVATION FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Activation function Sogmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE CNN MODEL IS DEFINED BELOW\n",
    "# THE CNN MODEL CONSISTS OF THREE CONVOLUTIONAL LAYERS AND TWO FULLY CONNECTED LAYERS\n",
    "# A MAX POOLING LAYER IS USED TO REDUCE THE DIMENSIONALITY OF THE DATA\n",
    "# THIS MAX POOL LAYER IS APPLIED BETWEEN THE CONVOLUTIONAL LAYERS AND THE FULLY CONNECTED LAYERS\n",
    "# A DROPOUT LAYER IS USED TO PREVENT OVERFITTING\n",
    "\n",
    "# THE FIRST CONV LAYER HAS 32 FILTERS, THE SECOND CONV LAYER HAS 64 FILTERS AND THE THIRD CONV LAYER HAS 128 FILTERS\n",
    "# THE STRIDE OF 1 MEANS THAT THE FILTER MOVES ONE PIXEL AT A TIME\n",
    "# THE PADDING OF 1 MEANS THAT THE INPUT IMAGE IS PADDDED WITH ZEROS TO MAINTAIN THE SAME DIMENSIONALITY\n",
    "# THE KERNEL SIZE OF 3 MEANS THAT THE FILTER SIZE IS 3X3\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # THIS FUNCTION DESCRIBES THE FORWARD PASS OF THE CNN MODEL\n",
    "    # THE FORWARD FUNCTION DESCRIBES HOW THE DATA FLOWS THROUGH THE NETWORK\n",
    "    # THE RELU ACTIVATION FUNCTION IS USED AFTER EACH CONVOLUTIONAL LAYER AND FULLY CONNECTED LAYER\n",
    "    # THE RELU FUNCTION IS USED TO INTRODUCE NON-LINEARITY INTO THE MODEL\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.sigmoid(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(torch.sigmoid(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(torch.sigmoid(self.bn3(self.conv3(x))))\n",
    "        x = x.view(-1, 128 * 3 * 3)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# HERE IS THE CODE THAT ITERATES THROUGH THE MODEL AND TRAINS IT\n",
    "# THE MODEL IS INTILIAZED WITH THE CNN CLASS\n",
    "# THEN THE FOLLOWING ARE DEFINED:\n",
    "# THE LOSS FUNCTION (CROSS ENTROPY LOSS)\n",
    "# THE OPTIMIZER (ADAM OPTIMIZER)\n",
    "# THE LEARNING RATE (0.001)\n",
    "# THE NUMBER OF EPOCHS (10)\n",
    "\n",
    "\n",
    "# THEN EVALUATION IS PERFORMED: \n",
    "# THE TRAINING LOOP ITERATES THROUGH THE TRAINING DATA AND UPDATES THE WEIGHTS OF THE MODEL\n",
    "# THE MODEL IS THEN EVALUATED ON THE VALIDATION DATA TO CHECK FOR OVERFITTING\n",
    "\n",
    "model2 = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model2.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model2(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model2.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model2(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f\"Validation Loss: {val_loss / len(val_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model2, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  Activation function Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE CNN MODEL IS DEFINED BELOW\n",
    "# THE CNN MODEL CONSISTS OF THREE CONVOLUTIONAL LAYERS AND TWO FULLY CONNECTED LAYERS\n",
    "# A MAX POOLING LAYER IS USED TO REDUCE THE DIMENSIONALITY OF THE DATA\n",
    "# THIS MAX POOL LAYER IS APPLIED BETWEEN THE CONVOLUTIONAL LAYERS AND THE FULLY CONNECTED LAYERS\n",
    "# A DROPOUT LAYER IS USED TO PREVENT OVERFITTING\n",
    "\n",
    "# THE FIRST CONV LAYER HAS 32 FILTERS, THE SECOND CONV LAYER HAS 64 FILTERS AND THE THIRD CONV LAYER HAS 128 FILTERS\n",
    "# THE STRIDE OF 1 MEANS THAT THE FILTER MOVES ONE PIXEL AT A TIME\n",
    "# THE PADDING OF 1 MEANS THAT THE INPUT IMAGE IS PADDDED WITH ZEROS TO MAINTAIN THE SAME DIMENSIONALITY\n",
    "# THE KERNEL SIZE OF 3 MEANS THAT THE FILTER SIZE IS 3X3\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.tanh(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(torch.tanh(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(torch.tanh(self.bn3(self.conv3(x))))\n",
    "        x = x.view(-1, 128 * 3 * 3)\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE IS THE CODE THAT ITERATES THROUGH THE MODEL AND TRAINS IT\n",
    "# THE MODEL IS INTILIAZED WITH THE CNN CLASS\n",
    "# THEN THE FOLLOWING ARE DEFINED:\n",
    "# THE LOSS FUNCTION (CROSS ENTROPY LOSS)\n",
    "# THE OPTIMIZER (ADAM OPTIMIZER)\n",
    "# THE LEARNING RATE (0.001)\n",
    "# THE NUMBER OF EPOCHS (10)\n",
    "# ACTIVATION FUNCTION (TANH)\n",
    "\n",
    "\n",
    "# THEN EVALUATION IS PERFORMED: \n",
    "# THE TRAINING LOOP ITERATES THROUGH THE TRAINING DATA AND UPDATES THE WEIGHTS OF THE MODEL\n",
    "# THE MODEL IS THEN EVALUATED ON THE VALIDATION DATA TO CHECK FOR OVERFITTING\n",
    "\n",
    "model3 = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model3.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model3.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model3(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model3.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model3(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f\"Validation Loss: {val_loss / len(val_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model3, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Activation function Leaky ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE CNN MODEL IS DEFINED BELOW\n",
    "# THE CNN MODEL CONSISTS OF THREE CONVOLUTIONAL LAYERS AND TWO FULLY CONNECTED LAYERS\n",
    "# A MAX POOLING LAYER IS USED TO REDUCE THE DIMENSIONALITY OF THE DATA\n",
    "# THIS MAX POOL LAYER IS APPLIED BETWEEN THE CONVOLUTIONAL LAYERS AND THE FULLY CONNECTED LAYERS\n",
    "# A DROPOUT LAYER IS USED TO PREVENT OVERFITTING\n",
    "\n",
    "# THE FIRST CONV LAYER HAS 32 FILTERS, THE SECOND CONV LAYER HAS 64 FILTERS AND THE THIRD CONV LAYER HAS 128 FILTERS\n",
    "# THE STRIDE OF 1 MEANS THAT THE FILTER MOVES ONE PIXEL AT A TIME\n",
    "# THE PADDING OF 1 MEANS THAT THE INPUT IMAGE IS PADDDED WITH ZEROS TO MAINTAIN THE SAME DIMENSIONALITY\n",
    "# THE KERNEL SIZE OF 3 MEANS THAT THE FILTER SIZE IS 3X3\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn3(self.conv3(x))))\n",
    "        x = x.view(-1, 128 * 3 * 3)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE IS THE CODE THAT ITERATES THROUGH THE MODEL AND TRAINS IT\n",
    "# THE MODEL IS INTILIAZED WITH THE CNN CLASS\n",
    "# THEN THE FOLLOWING ARE DEFINED:\n",
    "# THE LOSS FUNCTION (CROSS ENTROPY LOSS)\n",
    "# THE OPTIMIZER (ADAM OPTIMIZER)\n",
    "# THE LEARNING RATE (0.001)\n",
    "# THE NUMBER OF EPOCHS (10)\n",
    "# ACTIVATION FUNCTION (Leaky RELU)\n",
    "\n",
    "\n",
    "# THEN EVALUATION IS PERFORMED: \n",
    "# THE TRAINING LOOP ITERATES THROUGH THE TRAINING DATA AND UPDATES THE WEIGHTS OF THE MODEL\n",
    "# THE MODEL IS THEN EVALUATED ON THE VALIDATION DATA TO CHECK FOR OVERFITTING\n",
    "\n",
    "model4 = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model4.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model4.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model4(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # Validation step\n",
    "    model4.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model4(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f\"Validation Loss: {val_loss / len(val_loader):.4f}, Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model4, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL FINDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model3 performs the best on training data amoung all of the models. We will use this Model in our Flask application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model3, r\"C:\\Users\\inspi\\OneDrive - FAST National University\\Melior\\Github\\Melior_Internship\\CNN_Implementation\\my_flask_app\\model\\mnist_cnn.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "melior",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
